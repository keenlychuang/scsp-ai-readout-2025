# OpenAI Notes

- Defense One: DC News Site.
- Katrina Mulligan: OpenAI is partnering with Defense Department, Department of Energy.
    - First time in history that this type of technology is “exclusiely” developed by the private sector, where electricity or other tech had the USG in conversation by default.
    - US National Labs reached out, the vision was more than commercial partnership.
    - Goes into an example on how reasoning/thinking (chain of thought) models are changing the paradigm.
    - 20 years in Gov. Difficult customer.
- Model weights for OpenAI have been directly deployed on USG infra. Model weights finished being transferred today.
- Two major concerns: High security concerns, highly specific and complex classified data.
- How do the wants of the national labs, natsec, differ from the public normally?
    - “Clarity of process”
    - Chain of thought reasoning “opens up” the black box, where models are more “interpretable”.
        - Note from the note taker: still not truly interpretable.
    - National labs get early access to the reasoning models, like the evaluation teams.
- National labs published a study about reasoning problems in the o3 model.
    - 3-6 months of a human phd from a reasoning model.
- The hype about reasoning models is somewhat adopted by OAI here. Not much clarity of the competition with China, Deepseek, or who created chain of thought.
    - “Moving the most valuable hard drive in the world”
- Tucker: Foundation models on scientific advancement and Energy Consumption
    - Katrina: one of the hopes is that the labs will help with breakthroughs on the energy side.
    - o3 is wildly good at GEOINT analysis (there’s a demo tomorrow). Like geoguesser.
- A different type of public/private partnership: building on the partnership with the national labs, giving the USG a seat at the table.
- Tucker claims that the technology is “democratized”, and even points out how the ideal of the USG or OpenAI is different from other companies. Interesting since OAI is not open-sourced.
- Katrina: we were 6 months to a year ahead. Now, she claims we’re at most a couple of months ahead of the adversaries.
    - Edelman poll: trust in AI globally
        - Trust in AI is in low 30s in the west
        - In the east/china: 70s
    - Could win on the innovation, but lose on the adoption.
    - Mentions safety research, but mostly brushes it aside. Quickly transitions to an example of electricity adoption. Ex: fear mongers with electricity killing elephants.
    - AI labs left on their own will not get all the answers we want to. Almost pro-bono. They’re losing money to the national labs.
        - OpenAI IS willing to sacrifice and work for the public good.
    - Highlights great risk of not adopting quickly
    - Less emphasis on the small, non-frontier AI companies
- Industrial base, Intelligence Community, Defense, National Labs are the big four projects.
    - These are prototype, value propositions.